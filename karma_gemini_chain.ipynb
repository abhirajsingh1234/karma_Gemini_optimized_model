{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c8b9e8-5684-4389-9242-32d0d24feda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies\n",
    "\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "import pandas\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from datasets import load_dataset\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bdd5c4d-de07-49f9-92c6-db402d3b774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset from HF and Convert to Pandas DataFrame\n",
    "\n",
    "\n",
    "\n",
    "# data=pandas.read_csv('Content_Storage_df.csv')\n",
    "# Content_Storage_df = pandas.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e385d4-1d7b-42c1-bcf4-44bbdc41f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_collection(\"vector_embeddings\")\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5c7deec-3600-4fe5-ae96-5fd5f4f5a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question, top_k=3):\n",
    "    embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "    question_embedding = embedding_fn([question])[0]\n",
    "\n",
    "    # Retrieve top-k matching documents\n",
    "    results = collection.query(\n",
    "        query_embeddings=[question_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    if results[\"documents\"]:\n",
    "        # print(results[\"documents\"])\n",
    "        flat_documents = [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "        return \" \".join(flat_documents) if flat_documents else \"No relevant context found.\"\n",
    "    \n",
    "    return \"No relevant context found.\"\n",
    "\n",
    "def retrieve_grader_function(question):\n",
    "    \n",
    "    chat_session = retrieve_grader_1.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "\n",
    "# Web search function using Tavily API\n",
    "def web_search(query, num_results=3):\n",
    "    api_key = \"your tavily api\"  # Get API key from environment variable\n",
    "    if not api_key:\n",
    "        raise ValueError(\"Tavily API key is missing! Set 'TAVILY_API_KEY' as an environment variable.\")\n",
    "\n",
    "    url = \"https://api.tavily.com/search\"  # Tavily API endpoint\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"  # Use Bearer Token authentication\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"num_results\": num_results\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)  # Use POST instead of GET\n",
    "        response.raise_for_status()  # Raise error for bad responses (4xx, 5xx)\n",
    "        data = response.json()\n",
    "        if \"results\" in data and data[\"results\"]:\n",
    "            return \"\\n\".join([res[\"content\"] for res in data[\"results\"]])\n",
    "        else:\n",
    "            return \"No results found.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching data: {e}\"\n",
    "\n",
    "def answer_generator_function(question):\n",
    "    \n",
    "    chat_session = answer_generator_2.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "    \n",
    "def hallucination_detection_function(question):\n",
    "    \n",
    "    chat_session = hallucination_detection_3.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "def question_resolving_detection_function(question):\n",
    "    \n",
    "    chat_session = question_resolving_detection_4.start_chat(\n",
    "                history=history\n",
    "            )\n",
    "    \n",
    "    response = chat_session.send_message(question)\n",
    "    \n",
    "    model_response=response.text\n",
    "    return model_response\n",
    "\n",
    "\n",
    "#Full Path\n",
    "def Full_Flow(question):\n",
    "    document = retrieve_context(question)\n",
    "\n",
    "\n",
    "    model_input = f\"question : {question} , document : {document}\"\n",
    "    output = retrieve_grader_function(model_input)\n",
    "    \n",
    "    if 'yes' in output:\n",
    "        print('document found in database')\n",
    "    elif 'no' in output:\n",
    "        print('searching web.....')\n",
    "        print('document found on web.....')\n",
    "        document = web_search(question)\n",
    "        if document == \"No results found.\":\n",
    "            print('no result found on web')\n",
    "            print('another alternative to be found for this.....')\n",
    "            return None\n",
    "    else:\n",
    "        print('unexpeted error at web document retrieval part')\n",
    "        \n",
    "    #Generation of answer based on context\n",
    "    model_input = f\"question : {question},context : {document}\"\n",
    "    answer = answer_generator_function(model_input)\n",
    "    print('answer fetched from document')\n",
    "\n",
    "    #Hallucination detection to check the correctness of answer\n",
    "    hallucination_check_input = f\"context : {document}, answer : {answer}\"\n",
    "    hallucination_output = hallucination_detection_function(hallucination_check_input)\n",
    "    if 'yes' in hallucination_output:\n",
    "        print('hallucination detected')\n",
    "        print('another alternative to be found for this.....')\n",
    "        return None\n",
    "    elif 'no' in hallucination_output:\n",
    "        print('no hallucination detected')\n",
    "        question_resolver_input = f' question: {question}, answer: {answer}'\n",
    "        question_resolver_output = question_resolving_detection_function(question_resolver_input)\n",
    "        if 'no' in question_resolver_output:\n",
    "            print('the generated answer do not resolve the query\\n')\n",
    "            print('another alternative to be found for this.....')\n",
    "            return None\n",
    "        elif 'yes' in question_resolver_output:\n",
    "            print('generated answer will resolve the query\\n\\n')\n",
    "            return 'answer :'+answer\n",
    "    else:\n",
    "        print('error at hallucination detection output')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7d6bfd2-2ebf-49fa-87ad-7b5443be97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8190,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "retrieve_grader_1 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are a grader assessing the relevance of a retrieved document to a user question. \n",
    "                        Give a binary score 'yes' or 'no' to indicate whether the document is relevant.\n",
    "                        Provide the binary score as JSON with a single key 'score'.\n",
    "                        input format is 'question : question , document : document'. \"\"\"\n",
    ")\n",
    "\n",
    "answer_generator_2 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are an AI assistant designed for question-answering tasks.  \n",
    "                        Use the provided context to generate accurate and relevant answers.  \n",
    "                        If the answer is not found in the context, respond with \"I don't know.\"  \n",
    "                        Keep your response concise, with a maximum of three sentences.  \n",
    "                        End with a positive thought related to the question. \"\"\"\n",
    ")\n",
    "hallucination_detection_3 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are verifying whether the model-generated answer is factually correct based on the provided context.  \n",
    "                        If the answer includes information not found in the context, classify it as hallucinated.  \n",
    "                        Respond with a JSON object containing a single key `\"hallucination\"`, with a value of `\"yes\"` or `\"no\"`.  \n",
    "                        \n",
    "                        Output Format:  \n",
    "                        {\n",
    "                          \"hallucination\": \"yes\"  // If the answer contains hallucinated information  \n",
    "                        }  \n",
    "                        {\n",
    "                          \"hallucination\": \"no\"   // If the answer is fully supported by the context  \n",
    "                        }   \"\"\"\n",
    ")\n",
    "question_resolving_detection_4 = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash-8b\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"\"\"You are a grader evaluating whether an answer is useful in resolving the given question.  \n",
    "                        Assess if the answer is relevant, clear, and provides sufficient information to address the question.  \n",
    "                        Respond with a JSON object containing a single key `\"score\"`, with a value of `\"yes\"` or `\"no\"`.  \n",
    "                        \n",
    "                        Input Format:  \n",
    "                        question: {question}, answer: {answer}  \n",
    "                        \n",
    "                        Output Format:  \n",
    "                        {\n",
    "                          \"score\": \"yes\"  // If the answer is useful  \n",
    "                        }  \n",
    "                        {\n",
    "                          \"score\": \"no\"   // If the answer is not useful  \n",
    "                        }  \n",
    "                        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "123ddd12-ec7f-4a99-9ad6-fe64780a3802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching web.....\n",
      "document found on web.....\n",
      "answer fetched from document\n",
      "no hallucination detected\n",
      "generated answer will resolve the query\n",
      "\n",
      "\n",
      "answer :Sachin Tendulkar is an Indian cricket player considered one of the greatest batsmen.  He was India's youngest Test cricketer at age 16 and scored a century on his first-class debut.  He holds numerous records, including scoring 10,000 runs in ODI competition.  His incredible career is inspiring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history=[]\n",
    "\n",
    "question = 'who is sachin tendulkar?'\n",
    "answer = Full_Flow(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629059f-90b8-4d3e-85a0-1335ccecbda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ecd63-4aaa-45e0-a47c-dcf10dc12681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897e3a7-6f44-4a9a-81da-a77cdbcd32bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7921da-29bd-4df1-8776-9fce216fc0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3acc63-78d9-4913-8c8a-279500d280e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf498f2c-e548-45cd-8672-2ba2a5c7e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     escapers= ['exit']\n",
    "#     question = input('USER : ')\n",
    "#     answer= 'MAHARAJ :' + generate_answer(question)\n",
    " \n",
    "#     if question.lower() in escapers:\n",
    "#         break\n",
    "#     for char in answer:\n",
    "#         sys.stdout.write(char)  # Write character without newline\n",
    "#         sys.stdout.flush()      # Force immediate output\n",
    "#         time.sleep(0.05)         # Adjust speed\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4eb15-d349-4184-966b-0b72f72e7827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
